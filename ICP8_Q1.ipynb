{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ICP8_Q1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPyqWM0n/TOfQxYGbgAQD0W"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"rcs5yXhRAqyg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":79},"outputId":"58a8d11d-13a7-4cec-fe6a-1de804e85858","executionInfo":{"status":"ok","timestamp":1584725801547,"user_tz":300,"elapsed":5299,"user":{"displayName":"Akhil Kanugolu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe7G_hwY1i64J7fNi1Ap7tcj13_yIammEVl4ZC=s64","userId":"04692485770567792513"}}},"source":["import pandas\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","\n","# load dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"GtC1vu0TAuqg","colab_type":"code","colab":{}},"source":["dataset = pd.read_csv(\"diabetes.csv\", header=None).values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvCakVoXAxK1","colab_type":"code","colab":{}},"source":["X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],test_size=0.25, random_state=87)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-kVJyWQAzuX","colab_type":"code","colab":{}},"source":["np.random.seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zi0rrFcQA3XH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"59d5b387-cc26-41a9-ed1d-00e24c5afac1","executionInfo":{"status":"ok","timestamp":1584725891361,"user_tz":300,"elapsed":4360,"user":{"displayName":"Akhil Kanugolu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe7G_hwY1i64J7fNi1Ap7tcj13_yIammEVl4ZC=s64","userId":"04692485770567792513"}}},"source":["my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(50, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","576/576 [==============================] - 1s 1ms/step - loss: 7.7164 - acc: 0.3663\n","Epoch 2/100\n","576/576 [==============================] - 0s 50us/step - loss: 2.3467 - acc: 0.6406\n","Epoch 3/100\n","576/576 [==============================] - 0s 48us/step - loss: 1.3517 - acc: 0.6094\n","Epoch 4/100\n","576/576 [==============================] - 0s 44us/step - loss: 1.1781 - acc: 0.6406\n","Epoch 5/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.9748 - acc: 0.6424\n","Epoch 6/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.9272 - acc: 0.6562\n","Epoch 7/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.8566 - acc: 0.6476\n","Epoch 8/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.8012 - acc: 0.6632\n","Epoch 9/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.7761 - acc: 0.6788\n","Epoch 10/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.7776 - acc: 0.6615\n","Epoch 11/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.7305 - acc: 0.6580\n","Epoch 12/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.7176 - acc: 0.6684\n","Epoch 13/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.6736 - acc: 0.6910\n","Epoch 14/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6493 - acc: 0.6997\n","Epoch 15/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6245 - acc: 0.7049\n","Epoch 16/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.6107 - acc: 0.7066\n","Epoch 17/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6036 - acc: 0.7170\n","Epoch 18/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.6392 - acc: 0.6892\n","Epoch 19/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.6327 - acc: 0.6997\n","Epoch 20/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5979 - acc: 0.7188\n","Epoch 21/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5938 - acc: 0.7188\n","Epoch 22/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5810 - acc: 0.7188\n","Epoch 23/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5721 - acc: 0.7240\n","Epoch 24/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5888 - acc: 0.7257\n","Epoch 25/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5881 - acc: 0.7274\n","Epoch 26/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5824 - acc: 0.7257\n","Epoch 27/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5662 - acc: 0.7274\n","Epoch 28/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5632 - acc: 0.7205\n","Epoch 29/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5789 - acc: 0.7118\n","Epoch 30/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5540 - acc: 0.7222\n","Epoch 31/100\n","576/576 [==============================] - 0s 69us/step - loss: 0.5612 - acc: 0.7049\n","Epoch 32/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5742 - acc: 0.7188\n","Epoch 33/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5882 - acc: 0.7153\n","Epoch 34/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5695 - acc: 0.7205\n","Epoch 35/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5575 - acc: 0.7188\n","Epoch 36/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5519 - acc: 0.7431\n","Epoch 37/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5962 - acc: 0.7240\n","Epoch 38/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5921 - acc: 0.7066\n","Epoch 39/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5727 - acc: 0.7170\n","Epoch 40/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5448 - acc: 0.7292\n","Epoch 41/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5741 - acc: 0.7309\n","Epoch 42/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5616 - acc: 0.7396\n","Epoch 43/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5555 - acc: 0.7188\n","Epoch 44/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5645 - acc: 0.7413\n","Epoch 45/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5475 - acc: 0.7431\n","Epoch 46/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5442 - acc: 0.7257\n","Epoch 47/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5510 - acc: 0.7361\n","Epoch 48/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5800 - acc: 0.7170\n","Epoch 49/100\n","576/576 [==============================] - 0s 62us/step - loss: 0.5590 - acc: 0.7309\n","Epoch 50/100\n","576/576 [==============================] - 0s 58us/step - loss: 0.5501 - acc: 0.7413\n","Epoch 51/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5529 - acc: 0.7361\n","Epoch 52/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5230 - acc: 0.7483\n","Epoch 53/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5505 - acc: 0.7257\n","Epoch 54/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5920 - acc: 0.7101\n","Epoch 55/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6083 - acc: 0.7031\n","Epoch 56/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5303 - acc: 0.7222\n","Epoch 57/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5218 - acc: 0.7587\n","Epoch 58/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5542 - acc: 0.7465\n","Epoch 59/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5361 - acc: 0.7344\n","Epoch 60/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5404 - acc: 0.7500\n","Epoch 61/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5770 - acc: 0.7378\n","Epoch 62/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5458 - acc: 0.7292\n","Epoch 63/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5443 - acc: 0.7378\n","Epoch 64/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5104 - acc: 0.7708\n","Epoch 65/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5175 - acc: 0.7587\n","Epoch 66/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5140 - acc: 0.7604\n","Epoch 67/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5445 - acc: 0.7344\n","Epoch 68/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5444 - acc: 0.7535\n","Epoch 69/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5337 - acc: 0.7569\n","Epoch 70/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5213 - acc: 0.7431\n","Epoch 71/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5181 - acc: 0.7448\n","Epoch 72/100\n","576/576 [==============================] - 0s 60us/step - loss: 0.5246 - acc: 0.7517\n","Epoch 73/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5162 - acc: 0.7674\n","Epoch 74/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5223 - acc: 0.7604\n","Epoch 75/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5548 - acc: 0.7535\n","Epoch 76/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.6378 - acc: 0.6840\n","Epoch 77/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5367 - acc: 0.7569\n","Epoch 78/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5139 - acc: 0.7587\n","Epoch 79/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5178 - acc: 0.7622\n","Epoch 80/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5184 - acc: 0.7378\n","Epoch 81/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5462 - acc: 0.7431\n","Epoch 82/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5162 - acc: 0.7604\n","Epoch 83/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5144 - acc: 0.7639\n","Epoch 84/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5273 - acc: 0.7448\n","Epoch 85/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5359 - acc: 0.7274\n","Epoch 86/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5141 - acc: 0.7465\n","Epoch 87/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5215 - acc: 0.7517\n","Epoch 88/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5124 - acc: 0.7656\n","Epoch 89/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.4992 - acc: 0.7639\n","Epoch 90/100\n","576/576 [==============================] - 0s 58us/step - loss: 0.5172 - acc: 0.7500\n","Epoch 91/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5218 - acc: 0.7448\n","Epoch 92/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.4976 - acc: 0.7604\n","Epoch 93/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.4967 - acc: 0.7674\n","Epoch 94/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5169 - acc: 0.7552\n","Epoch 95/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5143 - acc: 0.7569\n","Epoch 96/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5051 - acc: 0.7656\n","Epoch 97/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5243 - acc: 0.7587\n","Epoch 98/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5312 - acc: 0.7604\n","Epoch 99/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5057 - acc: 0.7344\n","Epoch 100/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5200 - acc: 0.7465\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u0C3OdETBA1a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"332772e8-f0af-4d0f-a1a8-f035e9967011","executionInfo":{"status":"ok","timestamp":1584725929491,"user_tz":300,"elapsed":592,"user":{"displayName":"Akhil Kanugolu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe7G_hwY1i64J7fNi1Ap7tcj13_yIammEVl4ZC=s64","userId":"04692485770567792513"}}},"source":["print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 50)                450       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 51        \n","=================================================================\n","Total params: 501\n","Trainable params: 501\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","192/192 [==============================] - 0s 226us/step\n","[0.652181088924408, 0.7083333333333334]\n"],"name":"stdout"}]}]}